{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24dec82",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64d1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad27e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501d7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.read_csv('data/res_10.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25455046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LUACTRUU Index', 'SPX Index', 'BCOM Index', 'LBUSTRUU Index',\n",
       "       'LF98TRUU Index', 'LUATTRUU Index', 'LUMSTRUU Index',\n",
       "       'LBEATREU Index', 'LP01TREU Index', 'LG30TRUU Index',\n",
       "       'EMUSTRUU Index', 'LGTRTRUU Index', 'LGDRTRUU Index',\n",
       "       'LUGCTRUU Index', 'LP06TREU Index', 'LF94TRUU Index',\n",
       "       'LACHTRUU Index', 'LD08TRUU Index', 'LC07TRUU Index',\n",
       "       'USYC2Y10 Index', 'LECPTREU Index'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx['ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae5d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.load import get_y\n",
    "\n",
    "y_train, y_test = get_y('SPX Index', 'LUACTRUU Index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8743957a",
   "metadata": {},
   "source": [
    "# Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "547c092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = []\n",
    "MLFLOW_RUN_ID = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6160c93",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: Run with id=1 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\n\u001b[1;32m      6\u001b[0m mlflow\u001b[39m.\u001b[39mset_tracking_uri(\u001b[39m\"\u001b[39m\u001b[39mhttp://localhost:5000\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39;49mstart_run(run_id\u001b[39m=\u001b[39;49mMLFLOW_RUN_ID):\n\u001b[1;32m      8\u001b[0m     \u001b[39m#dummy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     dummy \u001b[39m=\u001b[39m DummyRegressor()\n\u001b[1;32m     10\u001b[0m     regressor_dummy  \u001b[39m=\u001b[39m RegressorDF(estimator\u001b[39m=\u001b[39mdummy, y_train\u001b[39m=\u001b[39my_train, y_test\u001b[39m=\u001b[39my_test)\n",
      "File \u001b[0;32m~/MPhil/m4benchmarkstudy/.venv/lib/python3.10/site-packages/mlflow/tracking/fluent.py:303\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, tags, description)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39mif\u001b[39;00m existing_run_id:\n\u001b[1;32m    302\u001b[0m     _validate_run_id(existing_run_id)\n\u001b[0;32m--> 303\u001b[0m     active_run_obj \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mget_run(existing_run_id)\n\u001b[1;32m    304\u001b[0m     \u001b[39m# Check to see if experiment_id from environment matches experiment_id from set_experiment()\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    306\u001b[0m         _active_experiment_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[39mand\u001b[39;00m _active_experiment_id \u001b[39m!=\u001b[39m active_run_obj\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mexperiment_id\n\u001b[1;32m    308\u001b[0m     ):\n",
      "File \u001b[0;32m~/MPhil/m4benchmarkstudy/.venv/lib/python3.10/site-packages/mlflow/tracking/client.py:167\u001b[0m, in \u001b[0;36mMlflowClient.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_run\u001b[39m(\u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Run:\n\u001b[1;32m    128\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m    contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39m        status: FINISHED\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mget_run(run_id)\n",
      "File \u001b[0;32m~/MPhil/m4benchmarkstudy/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:72\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mFetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mcontains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m         raises an exception.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m _validate_run_id(run_id)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mget_run(run_id)\n",
      "File \u001b[0;32m~/MPhil/m4benchmarkstudy/.venv/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:137\u001b[0m, in \u001b[0;36mRestStore.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mFetch the run from backend store\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39m:return: A single Run object if it exists, otherwise raises an Exception\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m req_body \u001b[39m=\u001b[39m message_to_json(GetRun(run_uuid\u001b[39m=\u001b[39mrun_id, run_id\u001b[39m=\u001b[39mrun_id))\n\u001b[0;32m--> 137\u001b[0m response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(GetRun, req_body)\n\u001b[1;32m    138\u001b[0m \u001b[39mreturn\u001b[39;00m Run\u001b[39m.\u001b[39mfrom_proto(response_proto\u001b[39m.\u001b[39mrun)\n",
      "File \u001b[0;32m~/MPhil/m4benchmarkstudy/.venv/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     57\u001b[0m endpoint, method \u001b[39m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     58\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[0;32m~/MPhil/m4benchmarkstudy/.venv/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:202\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    200\u001b[0m     call_kwargs[\u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m json_body\n\u001b[1;32m    201\u001b[0m     response \u001b[39m=\u001b[39m http_request(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 202\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    203\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    204\u001b[0m parse_dict(js_dict\u001b[39m=\u001b[39mjs_dict, message\u001b[39m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/MPhil/m4benchmarkstudy/.venv/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:134\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    133\u001b[0m     \u001b[39mif\u001b[39;00m _can_parse_as_json_object(response\u001b[39m.\u001b[39mtext):\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mraise\u001b[39;00m RestException(json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext))\n\u001b[1;32m    135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m         base_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    137\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI request to endpoint \u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfailed with error code \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m != 200\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_DOES_NOT_EXIST: Run with id=1 not found"
     ]
    }
   ],
   "source": [
    "from data.save_to_mlflow import save_to_mlflow\n",
    "from sktime.regression.dummy import DummyRegressor\n",
    "from dc_df.base import RegressorDF\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "with mlflow.start_run():\n",
    "    #dummy\n",
    "    dummy = DummyRegressor()\n",
    "    regressor_dummy  = RegressorDF(estimator=dummy, y_train=y_train, y_test=y_test)\n",
    "    dummy_pred  = regressor_dummy.fit_predict()\n",
    "\n",
    "    accuracy, f1,fpr, tpr, area_under_the_curve = regressor_dummy.evaluate()\n",
    "    tag = f\"{model_name}-dataset:{dts_name}\"\n",
    "    mlflow.set_tag(\"mlflow.runName\", tag )\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "    mlflow.log_metric('f1', f1)\n",
    "    mlflow.log_metric('fpr', fpr)\n",
    "    mlflow.log_metric('tpr', tpr)\n",
    "    mlflow.log_metric('auc', auc)\n",
    "\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dc_df.model_registry import HMMExogenousDC\n",
    "from data.save_to_mlflow import save_to_mlflow\n",
    "\n",
    "# exogenous model Random Forest with HMM\n",
    "\n",
    "regressor_rf = RandomForestRegressor(n_jobs=12)\n",
    "hmm_exogenous = HMMExogenousDC(estimator=regressor_rf, y_train=y_train, y_test=y_test, name= \"RF_HMM\" )\n",
    "y_pred, X = hmm_exogenous.fit_predict()\n",
    "accuracy, f1,fpr, tpr, area_under_the_curve = hmm_exogenous.evaluate()\n",
    "results_data.append(\n",
    "    (\"RF_HMM\", accuracy, f1,fpr[1], tpr[1], area_under_the_curve)\n",
    ")\n",
    "\n",
    "MLFLOW_RUN_ID = 1\n",
    "save_to_mlflow(model_name=hmm_exogenous.get_name(), dts_name='SPX-LUACTRUU', accuracy=accuracy, f1=f1, fpr=fpr, tpr=tpr, auc=area_under_the_curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a05109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f20c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "from dc_df.base import RegressorDF\n",
    "regressor_rf = RandomForestRegressor(n_jobs=12)\n",
    "\n",
    "regressor_dc_rf  = RegressorDF(estimator=regressor_rf, y_train=y_train, y_test=y_test)\n",
    "\n",
    "rf_pred = regressor_dc_rf.fit_predict()\n",
    "\n",
    "accuracy, f1,fpr, tpr, area_under_the_curve = regressor_dc_rf.evaluate()\n",
    "results_data.append(\n",
    "    (\"RF\", accuracy, f1,fpr[1], tpr[1], area_under_the_curve)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR\n",
    "regressor_svr = SVR()\n",
    "regressor_df_svr  = RegressorDF(estimator=regressor_svr, y_train=y_train, y_test=y_test)\n",
    "\n",
    "svr_pred = regressor_df_svr.fit_predict()\n",
    "\n",
    "accuracy, f1,fpr, tpr, area_under_the_curve = regressor_df_svr.evaluate()\n",
    "results_data.append(\n",
    "    (\"SVR\", accuracy, f1,fpr[1], tpr[1], area_under_the_curve)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dff312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR HMM\n",
    "regressor_svr = SVR()\n",
    "svr_hmm = HMMExogenousDC(estimator=regressor_svr, y_train=y_train, y_test=y_test )\n",
    "y_pred, X = svr_hmm.fit_predict()\n",
    "\n",
    "accuracy, f1,fpr, tpr, area_under_the_curve = svr_hmm.evaluate()\n",
    "results_data.append(\n",
    "    (\"SVR_HMM\", accuracy, f1,fpr[1], tpr[1], area_under_the_curve)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651517e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression\n",
    "regressor_lasso = linear_model.Lasso()\n",
    "regressor_dc_lasso  = RegressorDF(estimator=regressor_lasso, y_train=y_train, y_test=y_test)\n",
    "lasso_pred  = regressor_dc_lasso.fit_predict()\n",
    "\n",
    "accuracy, f1,fpr, tpr, area_under_the_curve = regressor_dc_lasso.evaluate()\n",
    "results_data.append(\n",
    "    (\"LASSO\", accuracy, f1,fpr[1], tpr[1], area_under_the_curve)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7062a",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae96433",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(columns=['estimator','accuracy','f1','fpr','tpr','auc'], data=results_data)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_m4study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
